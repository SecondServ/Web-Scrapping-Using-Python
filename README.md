# Web-Scraping-Using-Python
### Definition (from Wikipedia)
Web scraping, web harvesting, or web data extraction is data scraping used for extracting data from websites. Web scraping software may access the World Wide Web directly using the Hypertext Transfer Protocol, or through a web browser. While web scraping can be done manually by a software user, the term typically refers to automated processes implemented using a bot or web crawler. It is a form of copying, in which specific data is gathered and copied from the web, typically into a central local database or spreadsheet, for later retrieval or analysis.

### Content
This repo includes four representative web scrapping instances I have done using Python, covering:
- Basic Web scraping technique
- **Coroutine** + **Queue** Web scraping
- Automate browser using **Selenium**
- **Scrapy Framework**

### Detailed Description
##### 1. Douban Crawler
- Function: Gether all the song names, lyrics, lyricist's names and composers' names of Jay Chou's published music listed on the first 3 pages at y.qq.com
- Technique: Basic Web scraping technique

##### 2. Calories Crawler
- Function: Gether ingredient names, calorie information and links listed on the first 3 pages at boohee.com
- Technique: Coroutine + Queue Web scraping

##### 3. Automated Browser
- Function: Automatically control the Chrome broswer to open any website and login/leave a comment
- Technique: Selenium

##### 4. Dangdang Crawler
- Function: Gather book names, authors, ratings and prices listed on the first 3 pages of 2018 TOP500 book list at dangdang.com .
- Technique: Scrapy Framework




